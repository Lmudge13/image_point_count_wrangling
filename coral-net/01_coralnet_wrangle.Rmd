---
title: "How to quickly wrangle, clean, and summarize your CoralNet data"
author: "lkm"
date: "March 14, 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

# What you need to get started:  

* DATA: your exported annotations file from CoralNet 
* METADATA: your exported metadata file from CoralNet
* LABELS: provided in the github repo (04_coralnet_labelset.csv) (see below). This includes the full name and functional group for each [CoralNet label](https://coralnet.ucsd.edu/label/list/).You will need to download and edit your own copy if you used labels other than those already on CoralNet as of March 2018. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse) #install.packages(tidyverse)
library(janitor)
library(ggplot2)

#check your working directory
getwd()

#Note: Change your working directory, if necessary. The working directly should be the folder your data is stored in.
#setwd()
```

#Importing data 
Here you will create variables: data, metadata, and labelset. We've provided a sample data set situated on the GitHub repo for you to play around with if you want or you can add your own filename paths to import your own data. 

**Sample data set:** here we are reading in the data, metadata and labelset files from the image_point_count_wrangle github repo:

```{r import_sampledata, echo=TRUE, message=FALSE}

data <- read_csv ("https://raw.githubusercontent.com/Lmudge13/image_point_count_wrangling/master/coral-net/02_sample_data_annotations_simple_coralnet.csv")

metadata <- read_csv("https://raw.githubusercontent.com/Lmudge13/image_point_count_wrangling/master/coral-net/03_sample_metadata_coralnet.csv")

labelset <- read_csv("https://raw.githubusercontent.com/Lmudge13/image_point_count_wrangling/master/coral-net/04_coralnet_labelset.csv")

#The labelset file provides additional information on the organisms full name and their relevant functional group based on the set of short code labels typically used by CoralNet users.This extra information is not provided in the data output from CoralNet and therefore needs to be imported separately.

```

**Example code to import your own data, metadata and labels**
```{r import_owndata, message=FALSE}
## Don't forget to remove the # to run this chunk (and add a # in front of the sample data set code (or delete it) if you don't wish to use it.

#data <- read_csv ("add filename path")

#metadata <- read_csv ("add filename path")

#labelset <- read_csv("https://raw.githubusercontent.com/Lmudge13/image_point_count_wrangling/master/coral-net/04_coralnet_labelset.csv"). 

#Don't forget to edit the labelset filename path if you had to made modifications to this file.

```


```{r functions, echo=FALSE}

## add code for functions here

```


# Merging and tidying your data 
Here you will create the variable 'pointcount' by merging your data, metadata and labels into one data frame. Then you will reformat the column headings into snake_case so they are computer-readable. Your metadata columns might have different names, based on the metadata you entered into CoralNet. Here, we give an example of metadata that includes site and transect, as these are commonly used metrics for analyzing data.  

```{r main, echo=TRUE, message=FALSE}


## Merge together the data & metadata outputs from CoralNet:
pointcount <- dplyr::left_join(data, metadata, by ="Name")


## Now merge the labels to the pointcount dataset
pointcount <- dplyr::left_join(pointcount, labelset, by ="Label")


## Tidy up the column names on the pointcount dataframe:
pointcount<- janitor::clean_names(pointcount)

# Take a look at your dataframe. Here we use glimpse() instead of head() as it flips the column headings so you can see them all. You'll notice a number of the columns are filled with 'NA' i.e. not applicable, i.e. no data. (<chr> = character i.e. text and <int> = integer i.e. a whole number)
glimpse(pointcount)

## You can remove the columns with NA in all of the cells with janitor (if you want to keep the NA columns add a # infront of this code)
pointcount <- remove_empty_cols(pointcount)

# Take a look at your dataframe now:
glimpse(pointcount)
head(pointcount)
```

# Summarizing your pointcount data:
```{r summarize}

# Quick way to get a total frequency count on a column of interest i.e. how many times did you see each organism across all your photos:
plyr::count(pointcount$full_name)
#plyr::count(pointcount$label)- same thing but listed by label instead

#Count number of unique observation type (organism/benthos type etc.) in your dataset i.e. get a list of the observation types you saw across all your photos:
unique(pointcount$full_name)

# Or to just see how many unique observations you have for all columns:
pointcount %>% summarise_all(funs(n_distinct(.)))

#Here you can remove additional columns if they contain the same value throughout i.e. provide no information. Here I will remove "height_cm" as every cell is the same.
pointcount$height_cm <- NULL

#Now you can see we are left with 10 columns

pointcount %>% summarise_all(funs(n_distinct(.)))

```

## Calculate percent cover, using labels:  
* Across all sites  
* For each site  
* By site and transect  

```{r labels}

# Percent cover of all labels, across all sites in your pointcount dataset:
perc_cov_lab<-pointcount %>%
  dplyr::group_by(label) %>%
  dplyr::summarise (n = n()) %>%
  dplyr::mutate(perc_cov = n / sum(n)*100)

ggplot(data = perc_cov_lab, aes(y=perc_cov, x=label, color = perc_cov, fill = perc_cov)) + geom_col()  + theme(axis.text.x=element_text(angle = 60, hjust = 1))

# Percent cover of each label, for each site in the dataset:
perc_cov_lab_site<- pointcount %>%
  dplyr::group_by(site, label) %>%
  dplyr::summarise (n = n()) %>%
  dplyr::mutate(perc_cov = n / sum(n)*100)

# Percent cover of each label, by site & transect 
perc_cov_lab_site_trans<-pointcount %>%
  dplyr::group_by(site, transect, label) %>%
  dplyr::summarise (n = n()) %>%
  dplyr::mutate(perc_cov = n / sum(n)*100)


```

## Calculate percent cover, based on functional groups:
* Across all sites  
* % cover by site  
* % cover by site and transect  
```{r functional}

# Percent cover of all functional groups, across all sites in your pointcount dataset:

perc_cov_funct<- pointcount %>%
  dplyr::group_by(functional_group) %>%
  dplyr::summarise (n = n()) %>%
  dplyr::mutate(perc_cov = n / sum(n)*100)


# Percent cover of each functional group, for each site in the dataset:
perc_cov_funct_site<-pointcount %>%
  dplyr::group_by(site, functional_group) %>%
  dplyr::summarise (n = n()) %>%
  dplyr::mutate(perc_cov = n / sum(n)*100)

# Percent cover of each functional group, by site & transect
perc_cov_funct_site_trans<- pointcount %>%
  dplyr::group_by(site, transect, functional_group) %>%
  dplyr::summarise (n = n()) %>%
  dplyr::mutate(perc_cov = n / sum(n)*100)
```


